#!/usr/bin/python
# -*- coding: utf-8 -*-

#import httplib
#import re
import sys
PY2 = sys.version_info.major == 2
import os
import socket
import json
#import Cookie

#import string, xbmc, xbmcgui, xbmcplugin, xbmcaddon
#-------------------------------
import time, random
if PY2:
	import urllib, urllib2
else:
	import urllib.parse as urllib
	import urllib.request as urllib2
#from time import gmtime, strftime
#from urlparse import urlparse
socket.setdefaulttimeout(30)

#-----------------------------------------
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from random_ua import get_ua


siteUrl = 'jacred.xyz'
try:
	import xbmc, xbmcgui, xbmcplugin, xbmcaddon
	__settings__ = xbmcaddon.Addon()
	sUrl = __settings__.getSetting('jacred_url')
	if sUrl and sUrl !='': siteUrl = sUrl
except ImportError:
	pass
httpSiteUrl = 'http://' + siteUrl


try:
	if PY2:
		from xbmc import translatePath
	else:
		from xbmcvfs import translatePath
except ImportError:
	def translatePath(p):
		p = p.replace('special:/', os.path.dirname(__file__))
		if not os.path.exists(p): os.mkdir(p)
		return p

# - ====================================== antizapret ====================================================
#import time, cookielib
#sid_file = os.path.join(translatePath('special://temp/'), 'vpn.sid')
#cj = cookielib.FileCookieJar(sid_file)
#hr  = urllib2.HTTPCookieProcessor(cj)
#Lthread=[]


def ru(x):return unicode(x,'utf8', 'ignore')
def xt(x):return translatePath(x)
def rt(x):#('&#39;','’'), ('&#145;','‘')
	L=[('&quot;','"'), ('&amp;',"&"),('&#133;','…'),('&#38;','&'),('&#34;','"'), ('&#39;','"'), ('&#145;','"'), ('&#146;','"'), ('&#147;','“'), ('&#148;','”'), ('&#149;','•'), ('&#150;','–'), ('&#151;','—'), ('&#152;','?'), ('&#153;','™'), ('&#154;','s'), ('&#155;','›'), ('&#156;','?'), ('&#157;',''), ('&#158;','z'), ('&#159;','Y'), ('&#160;',''), ('&#161;','?'), ('&#162;','?'), ('&#163;','?'), ('&#164;','¤'), ('&#165;','?'), ('&#166;','¦'), ('&#167;','§'), ('&#168;','?'), ('&#169;','©'), ('&#170;','?'), ('&#171;','«'), ('&#172;','¬'), ('&#173;',''), ('&#174;','®'), ('&#175;','?'), ('&#176;','°'), ('&#177;','±'), ('&#178;','?'), ('&#179;','?'), ('&#180;','?'), ('&#181;','µ'), ('&#182;','¶'), ('&#183;','·'), ('&#184;','?'), ('&#185;','?'), ('&#186;','?'), ('&#187;','»'), ('&#188;','?'), ('&#189;','?'), ('&#190;','?'), ('&#191;','?'), ('&#192;','A'), ('&#193;','A'), ('&#194;','A'), ('&#195;','A'), ('&#196;','A'), ('&#197;','A'), ('&#198;','?'), ('&#199;','C'), ('&#200;','E'), ('&#201;','E'), ('&#202;','E'), ('&#203;','E'), ('&#204;','I'), ('&#205;','I'), ('&#206;','I'), ('&#207;','I'), ('&#208;','?'), ('&#209;','N'), ('&#210;','O'), ('&#211;','O'), ('&#212;','O'), ('&#213;','O'), ('&#214;','O'), ('&#215;','?'), ('&#216;','O'), ('&#217;','U'), ('&#218;','U'), ('&#219;','U'), ('&#220;','U'), ('&#221;','Y'), ('&#222;','?'), ('&#223;','?'), ('&#224;','a'), ('&#225;','a'), ('&#226;','a'), ('&#227;','a'), ('&#228;','a'), ('&#229;','a'), ('&#230;','?'), ('&#231;','c'), ('&#232;','e'), ('&#233;','e'), ('&#234;','e'), ('&#235;','e'), ('&#236;','i'), ('&#237;','i'), ('&#238;','i'), ('&#239;','i'), ('&#240;','?'), ('&#241;','n'), ('&#242;','o'), ('&#243;','o'), ('&#244;','o'), ('&#245;','o'), ('&#246;','o'), ('&#247;','?'), ('&#248;','o'), ('&#249;','u'), ('&#250;','u'), ('&#251;','u'), ('&#252;','u'), ('&#253;','y'), ('&#254;','?'), ('&#255;','y'), ('&laquo;','"'), ('&raquo;','"'), ('&nbsp;',' ')]
	for i in L:
		x=x.replace(i[0], i[1])
	return x

def mfindal(http, ss, es):
	L=[]
	while http.find(es)>0:
		s=http.find(ss)
		e=http.find(es)
		i=http[s:e]
		L.append(i)
		http=http[e+2:]
	return L

def mfind(t,s,e):
	r=t[t.find(s)+len(s):]
	r2=r[:r.find(e)]
	return r2

def rulower(str):
	str=str.strip()
	str=xt(str).lower()
	str=str.replace('Й','й')
	str=str.replace('Ц','ц')
	str=str.replace('У','у')
	str=str.replace('К','к')
	str=str.replace('Е','е')
	str=str.replace('Н','н')
	str=str.replace('Г','г')
	str=str.replace('Ш','ш')
	str=str.replace('Щ','щ')
	str=str.replace('З','з')
	str=str.replace('Х','х')
	str=str.replace('Ъ','ъ')
	str=str.replace('Ф','ф')
	str=str.replace('Ы','ы')
	str=str.replace('В','в')
	str=str.replace('А','а')
	str=str.replace('П','п')
	str=str.replace('Р','р')
	str=str.replace('О','о')
	str=str.replace('Л','л')
	str=str.replace('Д','д')
	str=str.replace('Ж','ж')
	str=str.replace('Э','э')
	str=str.replace('Я','я')
	str=str.replace('Ч','ч')
	str=str.replace('С','с')
	str=str.replace('М','м')
	str=str.replace('И','и')
	str=str.replace('Т','т')
	str=str.replace('Ь','ь')
	str=str.replace('Б','б')
	str=str.replace('Ю','ю')
	return str

def lower(s):
	try:s=s.decode('utf-8')
	except: pass
	try:s=s.decode('windows-1251')
	except: pass
	s=s.lower().encode('utf-8')
	return s


def GET(target, referer=httpSiteUrl, post=None, cookie=True):
	try:
		req = urllib2.Request(url = target, data = post)
		req.add_header('User-Agent', get_ua()) #'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C)')
		req.add_header('accept-encoding', 'gzip')
		req.add_header('Referer', referer)
		if cookie:
			cookiepath = os.path.join(translatePath('special://temp/'), 'jacred_tc.txt')
			if PY2:
				import cookielib
			else:
				import http.cookiejar as cookielib
			jar = cookielib.LWPCookieJar(cookiepath)
			if os.path.isfile(cookiepath): jar.load()
			opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(jar))
			resp = opener.open(req)
		else:
			resp = urllib2.urlopen(req)
		if resp.info().get('Content-Encoding') == 'gzip':
			if PY2:
				from StringIO import StringIO
			else:
				from io import BytesIO as StringIO
			import gzip
			buf = StringIO(resp.read())
			f = gzip.GzipFile(fileobj=buf)
			http = f.read()
		else:
			http=resp.read()
		resp.close()
		if cookie: jar.save()
		return http
	except Exception as e:
		print(e)
#		print(e.readlines())
		if '403:' in str(e) or '503:' in str(e):
			from cloudscraper import CloudScraper
			scraper = CloudScraper()
			try:
				c = scraper.get(target)
				if c.content.find(b'cloudflare.com/5xx-error'):
					print('cloudflare not bypassed!!!')
					raise
				return c.content
			except Exception as e:
				print (e)
				raise
		else:
			raise

def POST(target, post=None, referer=''):
	try:
		req = urllib2.Request(url = target, data = post)
		req.add_header('User-Agent', 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1) ; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET4.0C)')
		req.add_header('Referer', referer)
		#req.add_header('X-Requested-With', 'XMLHttpRequest')
		resp = urllib2.urlopen(req)
		http = resp.read()
		resp.close()
		return http
	except Exception as e:
		return ''

def get_magnet(url):
	print('====get_magnet===')
	s=GET(url)
	rez="magnet:"+mfind(s, "magnet:", "'>")
	return rez

def get_list(hp, t2, god):#, info):
	print('== get_list ==')
	L = json.loads(hp)
	if isinstance(L, dict): L = L.get('Results', L)
	print(len(L))
	#print(L[0])
	L2=[]
	st=time.time()
	for i in L:
		if t2 in i['title']:
			#print '===i===='
			#print(i)
			itm ={"sids":i.get('sid', '?'),"size":i.get('size', i.get('sizeName', '?')),
				"title":i['title'].encode('utf8') if PY2 else i['title'],
				"url":i['magnet'].encode('utf8') if PY2 else i['magnet'],
				"pageurl": i.get('url', '').encode('utf8') if PY2 else i.get('url', ''),
				"ttn": i['tracker'].encode('utf8') if PY2  else i['tracker'],
				"scr": "jacred"}
			if god:
				if god in i['title'] or int(god) == i.get('relased', 0):
					L2.append(itm)
			else:
				L2.append(itm)

	return L2



class Tracker:
	def __init__(self):
		pass

	def Search(self, info):
		print('====== jac.red =====')
		tmc = time.strftime('%d%y%m')
		t2=info['originaltitle']
		t1=info['title']
		god=info.get('year')
		url=httpSiteUrl+'/api/v1.0/torrents?search='+urllib.quote_plus(t1)
		print(url)
		GET(httpSiteUrl, cookie=False)
		hp=GET(url,cookie=False)
		#print(hp)
		if not PY2: hp=hp.decode('utf8')
		Lout=get_list(hp, t2, god) #, info)

		return Lout

	def Query(self, query):
#		try:
			god = None
			if '(' in query:
				god = query.split('(')[1].split(')')[0].strip()
				#print(god)
				query = query.split('(')[0].strip()
				#print(query)
			rez = self.Search({'originaltitle': '', 'title': query, 'year': god})
			return rez
#		except Exception as e:
			print(e)
			if ' 404:' not in str(e): raise
			return []

if __name__ == '__main__':
	#print(Tracker().Search({'originaltitle':'Терминатор','title':'Терминатор'}))
	print(Tracker().Query('Терминатор (1984)'))
	#print(Tracker().Query('Spider-Man: No way home (2021)'))
	#print(Tracker().Query('Spider-Man: No way home'))
	#print(Tracker().Query('Archive 81'))

